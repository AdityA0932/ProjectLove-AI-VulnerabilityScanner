import sys
import logging
from typing import List, Tuple
import numpy as np
import os
import re
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from transformers import BertTokenizer, TFBertForSequenceClassification
import tensorflow as tf

print(f"Python version: {sys.version}")
print(f"Python path: {sys.path}")

# Setup logging
logging.basicConfig(filename='logs/ai_module.log', level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')

class VulnerabilityDetector:
    def __init__(self, model_type='bert'):
        self.model_type = model_type
        self.model = None
        self.tokenizer = None
        self.vulnerability_patterns = {
            'Injection': r'(SELECT|INSERT|UPDATE|DELETE|UNION|DROP).*FROM',
            'Broken_Authentication': r'(password|user|login|auth)=',
            'Sensitive_Data_Exposure': r'(credit_card|ssn|password)=\w+',
            'XML_External_Entities': r'<!ENTITY.*SYSTEM',
            'Broken_Access_Control': r'(admin|config|root)=true',
            'Security_Misconfiguration': r'(DEBUG|TRACE)=true',
            'Cross-Site_Scripting': r'<script>.*</script>',
            'Insecure_Deserialization': r'(pickle|marshal|yaml).loads',
            'Using_Components_with_Known_Vulnerabilities': r'version=(0|1|2|3)\.\d+\.\d+',
            'Insufficient_Logging_Monitoring': r'(log|monitor).*(OFF|NONE)'
        }

    def preprocess(self, requests):
        if isinstance(requests, np.ndarray):
            return requests  # Already preprocessed
        
        if self.model_type == 'bert':
            if self.tokenizer is None:
                self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
            return self.tokenizer(requests, padding=True, truncation=True, return_tensors="tf")
        else:  # For traditional ML models
            return requests

    def train(self, requests_data: List[str], labels: List[int]):
        X_train, X_test, y_train, y_test = train_test_split(requests_data, labels, test_size=0.2, random_state=42)

        X_train = self.preprocess(X_train)
        X_test = self.preprocess(X_test)
        y_train = np.array(y_train).reshape(-1, 1)  # Reshape to (n_samples, 1)
        y_test = np.array(y_test).reshape(-1, 1)  # Reshape to (n_samples, 1)

        if self.model_type == 'bert':
            self.model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)
            self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),
                               loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
                               metrics=['accuracy'])

            self.model.fit(X_train, y_train, epochs=3, batch_size=16, validation_split=0.2)

        # Evaluate the model
        y_pred = self.predict(X_test)
        print(classification_report(y_test, [pred[0] for pred in y_pred]))

    def identify_vulnerability_type(self, request: str) -> List[str]:
        detected_vulnerabilities = []
        for vuln_type, pattern in self.vulnerability_patterns.items():
            if re.search(pattern, request, re.IGNORECASE):
                detected_vulnerabilities.append(vuln_type)
        return detected_vulnerabilities

    def predict(self, requests: List[str]) -> List[Tuple[int, List[str]]]:
        X = self.preprocess(requests)
        if self.model_type == 'bert':
            predictions = self.model.predict(X)
            binary_predictions = (predictions.logits > 0).numpy().flatten()
        else:
            binary_predictions = self.model.predict(X)

        results = []
        for request, prediction in zip(requests, binary_predictions):
            if prediction == 1:
                vuln_types = self.identify_vulnerability_type(request)
                results.append((1, vuln_types))
            else:
                results.append((0, []))
        return results

    def save(self, model_path: str, tokenizer_path: str):
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        os.makedirs(os.path.dirname(tokenizer_path), exist_ok=True)

        self.model.save_pretrained(model_path)
        self.tokenizer.save_pretrained(tokenizer_path)

    def load(self, model_path: str, tokenizer_path: str):
        self.model = TFBertForSequenceClassification.from_pretrained(model_path)
        self.tokenizer = BertTokenizer.from_pretrained(tokenizer_path)

def log_vulnerability(request: str):
    """Log detected vulnerabilities."""
    logging.info(f'Vulnerability found in request: {request}')

def generate_synthetic_data(num_samples: int = 10000) -> Tuple[List[str], List[int]]:
    """Generate synthetic data for training, including various OWASP Top 10 vulnerabilities."""
    normal_requests = [
        f"GET /page{i}" for i in range(num_samples // 2)
    ]
    vulnerable_requests = [
        f"SELECT * FROM users WHERE id='{i}' OR '1'='1';" for i in range(num_samples // 10)
    ] + [
        f"<script>alert('XSS{i}')</script>" for i in range(num_samples // 10)
    ] + [
        f"password{i}=123456" for i in range(num_samples // 10)
    ] + [
        f"<!ENTITY xxe SYSTEM 'file:///etc/passwd'>" for i in range(num_samples // 10)
    ] + [
        f"admin=true&root=true" for i in range(num_samples // 10)
    ]
    
    requests = normal_requests + vulnerable_requests
    labels = [0] * len(normal_requests) + [1] * len(vulnerable_requests)
    
    return requests, labels

def perform_anomaly_detection(requests: List[str], model: VulnerabilityDetector) -> List[str]:
    """Perform anomaly detection on a batch of requests."""
    predictions = model.predict(requests)
    anomalies = [req for req, (pred, _) in zip(requests, predictions) if pred == 1]
    return anomalies

def time_series_analysis(requests: List[str], window_size: int = 10):
    """Perform simple time series analysis on requests."""
    import pandas as pd
    df = pd.DataFrame({'request': requests, 'timestamp': pd.date_range(start='2023-01-01', periods=len(requests), freq='S')})
    df.set_index('timestamp', inplace=True)
    return df.rolling(window=window_size).mean()

print("AI module loaded successfully.")